## InClass Activity

So let's jump into this a bit now and start running some analyses to help further our understanding of alpha, power, effect sizes and sample size!

**Effect Sizes - Cohen's D**

We will continue to focus on t-tests for this lab.  There are a number of different effect sizes to choose from in the field but in the lectures we have looked at one type of effect size - **Cohen's d**: the standardised difference between two means (in units of SD). The thing to note is that the formula is slightly different depending on the type of t-test used and it can sometimes change depending on who you read. For today, and this lab, let's go with the following formulas:

* One-sample t-test & paired-sample t-test:  

> $d = t\ / \sqrt(N)$

* Independent t-test: 

> $d = 2t\ / \sqrt(df)$


Let's now try out some calculations. We will start with just looking at effect sizes from t-tests before calculating power in later tasks.

### Task 1: Effect size from a one-sample t-test {#Ch8InClassQueT1}

* You run a one-sample t-test and discover a significant effect, t(25) = 3.24, p < .05. Calculate `d` and determine whether the effect size is small, medium or large.

`r hide("Helpful Hint")`
```{block, type ="info"}
* Use the appropriate formula from above for the one-sample t-tests. 
* You have been given a t-value and df (degrees of freedom), you still need to determine `n` before you calculate `d`. 
* According to Cohen (1988), the effect size is small (.2 to .5), medium (.5 to .8) or large (> .8).
```
`r unhide()`  
<br>

<span style="font-size: 22px; font-weight: bold; color: var(--green);">Quickfire Questions</span>  

Answering the following questions to check your answers. The solutions are at the bottom if you need them:

* Enter, in digits, how many people were run in this study: `r fitb("26", ignore_ws = TRUE)`
* Which of these codes is the appropritae calculation of `d` in this instance:`r mcq(c(answer = "d = t/sqrt(N)","d = 2t/sqrt(df)"))`
* Enter the correct value of `d` for this analysis rounded to 2 decimal places: `r fitb(c("0.64", ".64"), ignore_ws = TRUE)`
* According to Cohen (1988), the effect size for this t-test would probably be considered: `r mcq(c("small", answer = "medium", "large"))`  

### Task 2: Effect size from between-subjects t-test {#Ch8InClassQueT2}

* You run a between-subjects t-test and discover a significant effect, t(30) = 2.9, p < .05. Calculate `d` and determine whether the effect size is small, medium or large.

`r hide("Helpful Hint")`
```{block, type ="info"}
* Use the appropriate formula above for between-subjects t-tests. 
* According to Cohen (1988), the effect size is small (.2 to .5), medium (.5 to .8) or large (> .8).
```
`r unhide()`  
<br>

<span style="font-size: 22px; font-weight: bold; color: var(--green);">Quickfire Questions</span>  

Answering the following questions to check your answers. The solutions are at the bottom if you need them:

* Enter, in digits, how many people were run in this study: `r fitb("32", ignore_ws = TRUE)`
* Which of these codes is the appropritae calculation of `d` in this instance:`r mcq(c("d = t/sqrt(N)",answer = "d = 2t/sqrt(df)"))`
* Enter the correct value of `d` for this analysis rounded to 2 decimal places:  `r fitb(c("1.06"), ignore_ws = TRUE)`
* According to Cohen (1988), the effect size for this t-test would probably be considered: `r mcq(c("small", "medium", answer = "large"))`

### Task 3: Effect Size from matched-pairs t-test {#Ch8InClassQueT3}

* You run a matched-pairs t-test between an ASD sample and a non-ASD sample and discover a significant effect t(39) = 2.1, p < .05. How many people are there in each group? Calculate `d` and determine whether the effect size is small, medium or large.

`r hide("Helpful Hint")`
```{block, type ="info"}
* You need the df value to determine `N`.
* A matched pairs is treated like a paired-sample t-test but with two separate groups.
```
`r unhide()`  
<br>

<span style="font-size: 22px; font-weight: bold; color: var(--green);">Quickfire Questions</span>  

Answering the following questions to check your answers. The solutions are at the bottom if you need them:

* Enter, in digits, how many people were in each group in this study. Note, not the total number of participants: `r fitb("40", ignore_ws = TRUE)`
* Which of these codes is the appropritae calculation of `d` in this instance:`r mcq(c(answer = "d = t/sqrt(N)","d = 2t/sqrt(df)"))`
* Enter the correct value of `d` for this analysis rounded to 2 decimal places: `r fitb(c("0.33", ".33"), ignore_ws = TRUE)`
* According to Cohen (1988), the effect size for this t-test would probably be considered: `r mcq(c(answer = "small", "medium", "large"))`

`r hide("Explain This - I don't understand the number of people in each group answer!")`
```{block, type ="info"}
* df in a paired-samples and in a matched-pairs t-test is calculated as `df = N - 1`.  
* Conversely, to find the total number of participants: `N = df + 1`; so N = 40. 
* Given that this is a matched-pairs t-test, by design there has to be an equal number of participants in each group. Therefore 40 participants in each group. 
```
`r unhide()`  

### Task 4: t-value and effect size for a between-subjects Experiment {#Ch8InClassQueT4}

* You run a between-subjects design study and the descriptives tell you: **Group 1**, M = 10, SD = 1.3, n = 30; **Group 2**, M = 11, SD = 1.7, n = 30. Calculate `t` and `d` for this between-subjects experiment.

`r hide("Helpful Hint")`
```{block, type ="info"}  
* Before you can calculate `d` (using the appropriate formula for a between-subjects experiment), you need to first calculate `t` using the formula:  

`t = (Mean1 - Mean2)/sqrt((var1/n1) + (var2/n2))`

* `var` stands for variance in the above formula. Variance is not the same as the standard deviation, right? Variance is measured in squared units. So for this equation, if you require variance to calculate `t` and you have the standard deviation, then you need to remember that `var = SD^2`.
* Now you have your t-value, but for calculating `d` you also need degrees of freedom. Think about how you would calculate `df` for a between-subjects experiment, taking `n` for both Group 1 and Group 2 into account.
* Remember that convention is that people report the `t` and `d` values as positive.
```
`r unhide()`   
<br>

<span style="font-size: 22px; font-weight: bold; color: var(--green);">Quickfire Questions</span>  

Answering the following questions to check your answers. The solutions are at the bottom if you need them:

* Enter the correct `t-value` for this test, rounded to two decimal places: `r fitb(c("2.56","-2.56"))`

* Which of these codes is the appropritae calculation of `d` in this instance:`r mcq(c("d = t/sqrt(N)",answer = "d = 2t/sqrt(df)"))`
* Based on the above t-value above, enter the correct value of `d` for this analysis rounded to 2 decimal places: `r fitb(c(".67", "0.67"))`
* According to Cohen (1988), the effect size for this t-test would probably be described as: `r mcq(c("small", answer = "medium", "large"))`

**Excellent!** Now that you are comfortable with calculating effect sizes, we will look at using them to establish appropriate sample sizes for a given power. Remember, in analysis, in nearly all occasions we should set the effect size as the minimum effect size we are interested. This can be determined through discussion, through previous studies, through pilots studies, or through rules of thumb like Cohen (1988). However, also keep in mind that the lower the effect size, the larger the sample size you will need. Everything is a trade-off.

**Power Calculations**

Today we will use the function `power.t.test()` to run our calculations. This is a `stats` function, which is a very basic package, meaning that you probably do not need to install a package to run this function as it is generally there automatically.  However, in the lectures we have been using the `pwr` package library which has a very similar function called `pwr.t.test()`. Going forward we would recommend using the `pwr` package functions instead as they give more diversity in terms of tests and are actually easier to use. If you are using the Boyd Orr machines the `pwr` package is already installed and you will just need to call it like all other packages, e.g. `library(pwr)`. Do not attempt to install it yourself on the Boyd Orr machines. If you are using your own laptop then feel free to install it.  The reason we aren't using the `pwr` package in this lab is because we can't guarantee other machines across campus will have that package installed and that seems unfair on people without their own device. So feel free to explore the `pwr` package for future use, and we will create a version of this lab in the `pwr` library for you to practice with, but for now let's just use the base function `power.t.test()`.

Remember that for more information on this function, simply do `?power.t.test` in the console. On doing this you will see that `power.t.test()` takes a series of inputs:

* **n** - observations/participants **per group**
* **delta** - the difference between means
* **sd** - standard deviation; **note: if sd = 1 then delta = Cohen's d**
* **sig.level** or $\alpha$
* **power** or $1-\beta$
* **type** - the type of t-test; e.g. `"two.sample", "one.sample", "paired"`
* **alternative** - the type of hypothesis; `"two.sided", "one.sided"`

And it works on a leave one out principle. You give it all the info you have and it returns the element you are missing.  So, for example, say you needed to know how many people per group you would need to detect an effect size as low as `d = .4` with `power = .8`, `alpha = .05` in a `two.sample (between-subjects) t-test` on a `two.sided` hypothesis test.  You would do:

```{r pwr_example, eval=FALSE}
power.t.test(delta = .4,
             sd = 1,
             power = .8,
             sig.level = .05,
             alternative = "two.sided",
             type = "two.sample")
```

```{r pwr_example_out, echo=FALSE, message=FALSE}
n_test <- power.t.test(delta = .4, sd = 1,
                       power = .8,
                       sig.level = .05,
                       alternative = "two.sided",
                       type = "two.sample") %>% tidy() %>% pull(n)
```

And it would tell you that you would need `r n_test` people per condition. But you only get whole people and we like to be conservative on our estimates so we would actually run `r ceiling(n_test)` **per condition**. That is a lot of people!!!

Let's get started. **But before you start with this next task**, you will need to load in packages such as the `tidyverse` and `broom`.

### Task 5: Sample size for standard power one-sample t-test {#Ch8InClassQueT5}

* Assuming you are interested in detecting a minimum Cohen's d of **d = .23**, what would be the minimum number of participants you would need in a one-sample t-test, assuming **power = .8**, $\alpha$ **= .05**, on a two-sided hypothesis? 

Using a pipeline, store the answer as a single value called `sample_size` (e.g. think `tidy() %>% pull()`) and round up to the nearest whole participant. You will probably need to use `ceiling()` instead of `round()`. For example, `ceiling(1.1)` gives you `r ceiling(1.1)`. `ceiling()` always rounds up!

`r hide("Helpful Hint")`
```{block, type ="info"}
* Use the list of inputs above as a kind of checklist to clearly determine which inputs are known or unknown. This can help you enter the appropriate values to your code.
* The structure of the `power.t.test()` would be very similar to the one shown above except two.sample would become one.sample
* If sd = 1, delta = cohen's d
* You will also need to use `tidy() %>% pull(n)` to help you obtain the sample size and `%>% ceiling()` to round up to the nearest whole participant.
```
`r unhide()`  
<br>

<span style="font-size: 22px; font-weight: bold; color: var(--green);">Quickfire Questions</span>  

Answering the following question to check your answers. The solutions are at the bottom if you need them:

* Enter the minimum number of participants you would need in this one-sample t-test: `r fitb("151")`

### Task 6: Effect size from a high power between-subjects t-test {#Ch8InClassQueT6}

* Assuming you run a between-subjects t-test with 50 participants per group and want a power of .9, what would be the minimum effect size you can reliably detect? Assume standard $\alpha$ and alternative hypothesis settings. Using a pipeline, store the answer as a single value called `cohens` and round to two decimal places.

`r hide("Helpful Hint")`
```{block, type ="info"}
* Again, use the list of inputs above as a kind of checklist to clearly determine which inputs are known or unknown. This can help you enter the values to your code. 
* This time we know everything except delta. Assume `sd = 1`.
* You will also need to use `tidy()`, `pull()` to obtain Cohen's d, delta, and `round()` so the value is rounded to two decimal places.
```
`r unhide()`  
<br>

<span style="font-size: 22px; font-weight: bold; color: var(--green);">Quickfire Questions</span>  

Answering the following questions to check your answers. The solutions are at the bottom if you need them:

* Based on the information given, what will you set `type` as in the function? `r mcq(c("one.sample", answer = "two.sample"))`
* Based on the output, enter the minimum effect size you can reliably detect in this test, rounded to two decimal places: `r fitb(c(".65", "0.65"),ignore_ws = TRUE)`
* According to Cohen (1988), the effect size for this t-test is `r mcq(c("small", answer = "medium", "large"))`
* Say you run the study and find that the effect size determined is d = .50. Given what you know about power, select the statement that is true: `r mcq(c("the study is sufficiently powered as the analysis indicates you can detect only effect sizes smaller than d = .65",answer = "the study is underpowered as the analysis indicates you can detect only effect sizes larger than d = .65"))`

### Task 7: Power of Published Research {#Ch8InClassQueT7}

Thus far we have used hypothetical situations - now go look at the paper on the Open Stats lab website called <a href="https://sites.trinity.edu/osl/data-sets-and-activities/t-test-activities" target = "_blank">Does Music Convey Social Information to Infants?</a> - we looked at it a little in the lectures. You can download the pdf and look at it, but here we will determine the power of the significant t-tests reported in Experiment 1 under the Results section on Pg489. There is a one-sample t-test and a paired-samples t-test to consider, summarised below. Assume testing was at power = .8, alpha = .05. Based on your calculations are either of the stated effects underpowered?

1. one-sample: t(31) = 2.96, p = .006
2. paired t-test: t(31) = 2.42, p = .022

`r hide("Helpful Hint")`
```{block, type ="info"}
* A one-sample t-test and a paired t-test use the same formula for Cohen's d.
* To calculate n: `n = df + 1`.
* Calculate the achievable Cohens d for the studies and then calculate the established Cohen's d for the studies. 
```
`r unhide()`
<br>
<span style="font-size: 22px; font-weight: bold; color: var(--pink);">Group Discussion Point</span>

Which of the t-tests do you believe to be underpowered? Why do you think this may be? Additional information about this to further your discussion can be found in the solution to task 8 at the end of this activity.

<span style="font-size: 22px; font-weight: bold; color: var(--blue);">Job Done - Activity Complete!</span>

**Great!** So hopefully you are now starting to see the interaction between alpha, power, effect sizes, and sample size. We should always want really high powered studies and depending on the size of the effect we are interested in (small to large), and our $\alpha$ level, this will mean we will need to run more or less participants to make sure our study is well powered. Points to note:

* Lowering the $\alpha$ level (e.g. .05 to .01) will reduce the power.
* Lowering the effect size (e.g. .8 to .2) will reduce the power.
* Increasing power (.8 to .9) will require more participants.

A high-powered study looking to detect a small effect size at a low alpha will require a large number of participants!

You should now be ready to complete the Homework Assignment for this lab. **The assignment for this Lab is FORMATIVE and is NOT to be submitted and will NOT count towards the overall grade for this module.** However you are strongly encouraged to do the assignment as it will continue to boost your skills which you will need in future assignments. If you have any questions, please post them on the slack forum under the channel **#level2_2018**.
