## PreClass Activity

```{r lab2-preclass-data, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}
pong_data <- read_csv("./data/02-s01/preclass/PongBlueRedBack 1-16 Codebook.csv")
``` 

**Revisiting Tabular Data**

Remember from your previous experience that nearly all data in research methods is stored in two-dimensional tables, either called data-frames, tables or tibbles. There are other ways of storing data that you will discover in time but mainly we will be using tibbles (if you like more info, type `vignette("tibble")` in the console). A tibble is really just a table of data with columns and rows of information. But within that table you can get different types of data, i.e. numeric, integer, and character.

|Type of Data     | Description                                                  |
|:------------|:-------------------------------------------------------------| 
|Numeric     | Numbers including decimals  |
|Integer     | Numbers without decimals  |
|Character     | Tends to contain letters or be words                       |

<span style="font-size: 22px; font-weight: bold; color: var(--green);">Quickfire Questions</span>

What type of data would these most likely be:

* Male = `r mcq(c(answer = "Character","Numeric","Integer"))`

* 7.15 = `r mcq(c("Character",answer = "Numeric","Integer"))`

* 137 = `r mcq(c("Character","Numeric",answer = "Integer"))`

`r hide("Portfolio Point - Data types and levels of measurement")`
```{block, type ="info"}
There is a lot of different types of data and as well as different types of levels of measurements and it can get very confusing. It's important to try to remember which is which because you can only do certain types of analyses on certain types of data and certain types of measurements. For instance, you can't take the average of Characters just like you can't take the average of Categorical data. Likewise, you can do any maths on Numeric data, just like you can on Interval and Ratio data. Integer data is funny in that sometimes it is Ordinal and sometimes it is Interval, sometimes you should take the median, sometimes you should take the mean. The main point is to always know what type of data you are using and to think about what you can and cannot do with them.
```
`r unhide()`

### Revisiting the Wickham Six

The main way we teach data-wrangling skills is by using the Wickham Six verbs. These are part of the `tidyverse` package which we introduced to you in Level 1. We will look at some of the basics again here but keep in mind that to look back at last years' exercises to see how used these verbs. The Wickham Six are: 

|Function     | Description                                                  |
|:------------|:-------------------------------------------------------------| 
|select()     | Include or exclude certain variables (columns)             |
|filter()     | Include or exclude certain observations (rows)             |
|mutate()     | Creates new variables (columns)                              |
|arrange()    | Changes the order of observations (rows)                     |
|group_by()   | Organises the observations (rows) into groups                |
|summarise()  | Derives summary variables for groups of observations (rows)  |


### Learning to Wrangle: Is there a Chastity Belt on Perception

Today we are going to be using data from this recent paper: [Is there a Chastity Belt on Perception](http://journals.sagepub.com/doi/abs/10.1177/0956797617730892). You can read the full paper if you like, particularly if you are thinking about doing the action-perception registered report option, but we will summarise the paper for you. The paper asks, **does your ability to perform an action influence your perception?** For instance, does your ability to hit a tennis ball influence how fast you perceive the ball to be moving? Or to phrase another way, do expert tennis players perceive the ball moving slower than novice tennis players?  This experiment does not use tennis players however, they used the Pong task: "a computerised game in which participants aim to block moving balls with various sizes of paddles". A bit like a very classic retro arcade game. Participants tend to estimate the balls as moving faster when they have to block it with a smaller paddle as opposed to when they have a bigger paddle. You can read the paper to get more details if you wish but hopefully that gives enough of an idea to help you understand the wrangling we will do on the data. We have cleaned up the data a little to start with. Let's begin!

1. Download the data as a zip file from [this link](https://www.psy.gla.ac.uk/~phil/L2Labs_201819/semester_one/lab_02/prep/Level2_Lab2_PreclassData_Pong.zip) and save it to somewhere you have access. In the lab, use your `M:` drive.

2. Set your working directory to the same folder as the data. `Session >> Set Working Directory >> Choose Directory`

3. Open a new script and copy and paste the two lines below. Here we are a) bringing the `tidyverse` into our library and then b) loading in the data through the `read_csv()` function and storing it in the tibble called `pong_data`.

``` {r libraries, eval = FALSE, message = FALSE, warning = FALSE}
library("tidyverse")
pong_data <- read_csv("PongBlueRedBack 1-16 Codebook.csv")
``` 
  
`r hide("Help my data is not loading?")`
```{block, type = "info"}
The three most common mistakes we see are:

1. Make sure you have spelt the data file name **exactly** as it is shown. Spaces and everything. Do not change the name of the csv file, fix your code instead. The reason being is that if you have a different name for your file than someone else then your code is not reproducible.
2. Remember when uploading data we use `read_csv` which has an underscore, whereas the data file itself will have a dot in its name, `filename.csv`. 
3. Check that the datafile is actually in the folder you have set as your working directory. 
```
`r unhide()`  

<br>
```{block, type = "danger"}

**DO NOT install packages in the Boyd Orr labs; they are already there and just need called in through `library()`.** 

However, If you are using a computer at home and you haven't previously installed the `tidyverse` package on your own machine before, you will have to install it first, e.g. `install.packages("tidyverse")`.

```


4. Let's have a look at the `pong_data` and see how it is organized. Type `View(pong_data)` or `glimpse(pong_data)` in your Console window.

In the dataset you will see that each row (observation) represents one trial per participant and that there were 288 trials for each of the 16 participants. The columns (variables) we have in the dataset are as follows:

| Variable       |       Type         |           Description               |
|:--------------:|:-------------------|:------------------------------------|
| Participant        | integer            | participant number                  |
| JudgedSpeed   | integer            | speed judgement (1=fast, 0=slow)    |
| PaddleLength         | integer            | paddle length (pixels)              |
| BallSpeed          | integer            | ball speed (2 pixels/4ms)          |
| TrialNumber         | integer            | trial number                        |
| BackgroundColor      | character          | background display colour           |
| HitOrMiss         | integer            | hit ball=1, missed ball=0       |
| BlockNumber  | integer            | block number (out of 12 blocks)     |

We will use this data to master our skills of the Wickham Six verbs, taking each verb in turn and looking at it briefly. You should develop your skills by setting yourself new challenges based on the ones we set. There are **6 verbs to work through** and then after that we will briefly recap on two other functions before finishing with a quick look at pipes. Try everything out and let us know anything you can't quite get.

`r hide("Portfolio Point - The Wickham Six")`
```{block, type = "info"}
You will use the Wickham Six very frequently for wrangling your data so this would definitely be something you should be making notes about - not just the names, but how they work and any particular nuances that you spot.
```
`r unhide()`   

### The **`select()`** Function - to keep only specific columns

The `select()` function lets us pick out the variables within a dataset that we want to work with. For example, say in `pong_data` we wanted to only keep the columns `Participant`, `JudgedSpeed`, `PaddleLength`, `BallSpeed`, `TrialNumber`, and `HitOrMiss` but we don't need `BackgroundColor` or `BlockNumber`: 

``` {r selectdata, eval = FALSE}
# We can tell the function what variables we want to include
select(pong_data, Participant, JudgedSpeed, PaddleLength, BallSpeed, TrialNumber, HitOrMiss)

# or do it the opposite way by exclude through `-ColumnName`
select(pong_data, -BackgroundColor, -BlockNumber)

# `-BackgroundColor` means 'not BackgroundColor', so here you are saying all columns except `BackgroundColor` and `BlockNumber`. The minus sign is the key part!
```  


#### Task 1: Using the Select Function

1. Either by inclusion or exclusion, select only the columns `Participant`, `PaddleLength`, `TrialNumber`, `BackgroundColor` and `HitOrMiss` from `pong_data`.  
`select()` can also be used to reorder columns. 

2. Use `select()` to keep only the columns `Participant`, `JudgedSpeed`, `BallSpeed`, `TrialNumber`, and `HitOrMiss` but have them display in alphabetical order, left to right.

`r hide("Helpful Hint")`
```{block, type = "info"}

1. Have you remembered to include the dataset `pong_data`? Pay attention to upper/lower case letters and spelling!

2. Think about how you first entered the column names as they appeared. But what happens if you change the order that you enter the column names? 
```
`r unhide()`  

### The **`arrange()`** Function - to sort and arrange columns

The `arrange()` function sorts the rows in the tibble according to what column you tell it to sort by. 

``` {r arrangedata, eval = FALSE}
# You can arrange by one column e.g. by `BallSpeed`
arrange(pong_data, BallSpeed)

# Or by multiple columns e.g. by `BallSpeed` (fastest first) and `BackgroundColor`
arrange(pong_data, desc(BallSpeed), BackgroundColor) 
```
  
`r hide("Explain this - where did desc come from?")`
```{block, type = "info"}

* What does `desc()` do? 
    * `desc()` is how to sort by largest to smallest - i.e. descending order.
    * Compare the output of the two lines above on the `BallSpeed` column. 
    * Does `desc()` also work for `BackgroundColor`?
```
`r unhide()`  

#### Task 2: Arranging Data

1. Arrange the data by two variables: `HitOrMiss` (putting hits - 1 - first), and `JudgedSpeed` (fast judgement - 1 - first).  

### The **`filter()`** Function - to keep only parts of the data

The `filter()` function lets us parse out a subset of the data, meaning we keep only parts of the data.

``` {r filterdata1, eval= FALSE}
# we might want only the red `BackgroundColor` 
filter(pong_data, BackgroundColor == "red")

# or higher speeds above 4 pixels
filter(pong_data, BallSpeed > 4)

# or both!
filter(pong_data, BackgroundColor == "red", BallSpeed > 4)

# this can also be written as: 
filter(pong_data, BackgroundColor == "red" & BallSpeed > 4)

# or we might want to see specific Participants:
filter(pong_data, Participant %in% c("1", "3", "10", "14", "16")) 
# The c() creates a little container of items called a vector. 
# the `%in%` is called `group membership` and means keep each of these Participants

# or excluding a specific Participant
filter(pong_data, Participant != "7")
# you can read != as 'does not equal'. So keep all Participants except 7.
```  

#### Task 3: Using the Filter Function

1. Use `filter()` to extract all Participants that had a fast speed judgement, for speeds 2, 4, 5, and 7, but missed the ball. Store this remaining data in a variable called `pong_fast_miss`

`r hide("Helpful Hint")`
```{block, type = "info"}
There are three parts to this filter so it is best to think about them individually and then combine them.

1. Filter all fast speed judgements (`JudgedSpeed`)

2. Filter for the speeds 2, 4, 5 and 7 (`BallSpeed`)

3. Filter for all Misses (`HitOrMiss`)

You could do this in three filters where each one uses the output of the preceeding one, or remember that filter functions can take more than one arguement - see the example above. Also, because the `JudgedSpeed` and `HitOrMiss` are Integer you will need `==` instead of just `=`.
```
`r unhide()`

`r hide("Portfolio Point - And not Or")`
```{block, type = "info"}
The filter function is very useful but if used wrongly can give you very misleading findings. This is why it is very important to always check your data after you perform an action. Let's say you are working in comparative psychology and have run a study looking at how cats, dogs and horses perceive emotion. Let's say the data is all stored in the tibble `animal_data` and there is a column called `animals` that tells you what type of animal your participant was. Ok, so imagine you wanted all the data from just cats

`filter(animal_data, animals == "cat")`

Exactly! But what if you wanted cats and dogs?

`filter(animal_data, animals == "cat", animals == "dog")` 

Right? Wrong! This actually says "give me everything that is a cat and a dog". But nothing is a cat and a dog, that would be weird - like a dat or a cog! What you actually want is is everything that is either a cat **or** a dog, which is stated as:

`filter(animal_data, animals == "cat" | animals == "dog")` 

The vertical line `|` is the symbol for Or. 

**TOP TIP:** Always pay attention to what you want and most importantly to what your code produces.
```
`r unhide()`

### The **`mutate()`** Function - for adding new columns

The `mutate()` function lets us create a new variable in our dataset. For example, let's add a new column to `pong_data` in which the background color is converted into numeric form where `red` will become 1, and `blue` will become 2.

``` {r mutatedata, eval = FALSE}
pong_data <- mutate(pong_data, 
                    BackgroundColorNumeric = recode(BackgroundColor, 
                                                    "red" = 1, 
                                                    "blue" = 2))
```

The code here is is a bit complicated but:

* `BackgroundColorNumeric` is the name of your new column, 
* `BackgroundColor` is the name of the old column and the one to take information from,
* and 1 and 2 are the new codings of red and blue respectively.

The `mutate()` function is also handy for making some calculations on or across columns in your data. For example, say you realise you made a mistake in your experiment where your participant numbers should be 1 higher for every participant, i.e. Participant 1 should actually be numbered as Participant 2, etc. You would do something like:

``` {r mutatedata2, eval = FALSE}
pong_data <- mutate(pong_data, Participant = Participant + 1)
```
Note here that you are giving the new column the same name as the old column `Participant`. What happens here is that you are **overwriting the old data with the new data**! So watch out, mutate can create a new column or overwrite an existing column, depending on what you tell it to do!  

#### Task 4: Mutating Variables

* You realise another mistake in that all your trial numbers are wrong. The first trial (trial number 1) was a practice so should be excluded. And your experiment actually started on trial 2. Tidy this up by:

1. Creating a new variable and filtering out all trials with the number 1 (`TrialNumber` column) from `pong_data`, 
2. and then use the `mutate()` function to recount all the remaining trial numbers, starting them at one again instead of two. Save it in `pong_data`.

`r hide("Helpful Hint")`
```{block, type = "info"}
Step 1: 

* filter(`TrialNumber` does not equal 1) - remember to store this output in a variable?

Step 2: 

* mutate(`TrialNumber` = TrialNumber minus 1)
```
`r unhide()`  

### The **`group_by()`** Function - to group parts of data altogether

The `group_by()` function groups the rows in a dataset according to a category you specify, e.g. grouping all Male data together and all Female data together.

``` {r groupeddata, eval = FALSE}
# In this data we could group trials by `BackgroundColor`
group_by(pong_data, BackgroundColor)

# or by multiple criteria e.g. `HitOrMiss` and `BackgroundColor` 
group_by(pong_data, HitOrMiss, BackgroundColor)
```

Note that nothing actually appears to change in the data, unlike with the other functions, but a big operation has taken place. Look at the output in your console when you run `group_by(pong_data, BackgroundColor)`. At the top of the output notice that the 2nd line of the output tells us the grouping criteria and how many groups now exist: see the line `Groups: BackgroundColor [2]`: we grouped by `BackgroundColor` and there are `[2]` groups - one for red and one for blue.  


#### Task 5: Grouping Data

* Group the data by `BlockNumber` and by `BackgroundColor`, in that order, and then enter the number of groups (i.e. a number) you get as a result: `r fitb("24")`

`r hide("Helpful Hint")`
```{block, type = "info"}
It is the same procedure as this but with different column names:

`group_by(pong_data, HitOrMiss, BackgroundColor)`

The number of groups should be between the sum of the number of background colors (red and blue) and the number of blocks (12).
```
`r unhide()`  

`group_by()` is incredibly useful as once the data is organised into groups you can then apply other functions (`filter`, `arrange`, `mutate`...etc.) to the groups within your data that you are interested in, instead of to the entire dataset. For instance, a common second step after `group_by` might be to `summarise` the data...

### The **`summarise()`** Function - to do some calculations on the data

The `summarise()` function lets you calculate some descriptive statistics on your data. For example, say you want to know the number of hits there were for different paddle lengths, or number of hits there were when the background color was red or blue.

```{r datasummary, eval = FALSE}
# First we group the data accordingly, storing it in `pong_data_group`
pong_data_group <- group_by(pong_data, BackgroundColor, PaddleLength)

# And then we summarise it, storing the answer in `total_hits`
pong_data_hits <- summarise(pong_data_group, total_hits = sum(HitOrMiss))

# And then for fun we can filter just the red, small paddle hits
pong_data_hits_red_small <- filter(pong_data_hits, BackgroundColor == "red", PaddleLength == 50)
```

`summarise()` has a range of internal functions that make life really easy, e.g. `mean`, `sum`, `max`, `min`, etc. See the dplyr cheatsheets for more examples. 

#### Task 6: Summarising Data

* Run the first two lines of code in the box above to create `pong_data_hits` and then enter the number of hits made with the small paddle (50) and the red color background in this box: `r fitb("517")`

**Note:**

* The name of the column within `pong_data_hits` is `total_hits`; this is what you called it in the above code. You could have called it anything you wanted but always try to use something sensible.

* Make sure to call your variables something you (and anyone looking at your code) will understand and recognize later (i.e. not variable1, variable2, variable3. etc.), and avoid spaces (use_underscores_never_spaces). 

`r hide("Portfolio Point - the ungroup function")`
```{block, type = "info"}
After grouping data together using the `group_by()` function and then peforming a task on it, e.g. filter(), it can be very good practice to ungroup the data before performing another function. Forgetting to ungroup the dataset won't always affect further processing, but can really mess up other things. 

Again just a good reminder to always check the data you are getting out of a function a) makes sense and b) is what you expect.
```
`r unhide()`

<span style="font-size: 22px; font-weight: bold; color: var(--green);">Quickfire Questions</span>

* Which of the Wickham Six would I use to sort columns from smallest to largest: `r mcq(c("select","filter","mutate",answer ="arrange","group_by","summarise"))`

* Which of the Wickham Six would I use to calculate the mean of a column: `r mcq(c("select","filter","mutate","arrange","group_by",answer ="summarise"))`

* Which of the Wickham Six would I use to remove certain observations - e.g. remove all males: `r mcq(c("select",answer = "filter","mutate","arrange","group_by","summarise"))` 

### Two Other Useful Functions

The Wickham Six verbs let you to do a lot of things with data, however there are thousands of other functions at your disposal. If you want to do something with your data that you are not sure how to do using these functions, do a Google search for an alternative function - chances are someone else has had the same problem and has a help guide. For example, two other functions to note are the `bind_rows()` function and the `count()` functions. 

The `bind_rows()` function is useful if you want to combine two tibbles together into one larger tibble that have the same column structure. For example:    

``` {r bindexample, eval = FALSE}
# a tibble of ball speeds 1 and 2
slow_ball<- filter(pong_data, BallSpeed < 3) 

# a tibble of ball speeds 6 and 7
fast_ball <- filter(pong_data, BallSpeed >= 6) 

# a combined tibble of extreme ball speeds
extreme_balls <- bind_rows(slow_ball, fast_ball) 
```

Finally, the `count()` function is a shortcut that can sometimes be used to count up the number of rows you have for groups in your data, without having to use the `group_by()` and `summarise()` functions. For example, in Task 6 we combined `group_by()` and `summarise()` to calculate how many hits there were based on background color and paddle length. Alternatively we could have done:

``` {r countexample1, eval = FALSE}
count(pong_data, BackgroundColor, PaddleLength, HitOrMiss)
```

The results are the same, just that in the `count()` version we get all the information, including misses, because we are just counting rows. In the `summarise()` method we only got hits because that was the effect of what we summed. So two different methods give similar answers - coding can be individualised and get the same result!

### Last but not least - Pipes (**`%>%`**) to make your code efficient

By now you'll have noticed that`tidyverse` functions generally take the following grammatical structure (called **syntax**): `function_name(dataset, arg1, arg2,..., argN)` where the dataset is the entire tibble of data you ar eusing, and each argument (`arg`) is some operation on a particular column or variable, or the column name you want to work with. For example:   

``` {r syntax, eval = FALSE}
# function_name(dataset, arg1, arg2, ....)
filter(pong_data, PaddleLength == "50", BallSpeed > 4)

group_by(pong_data, BallSpeed, Participant)
```

In the first example, we are filtering the whole `pong_data` dataset by a particular paddle length, then by particular speeds. In the second, we are grouping by `BallSpeed` and then by `Participant`. Note that the order of arguments is specific as it performs argument1 then argument2, etc. Changing the order of arguments may give a different output. So the order you work in is important, and this is called your **pipeline**. For example, here is one we used above to find how many hits there with the small paddle length and the red background.

```{r datasummary-nopipe, eval = FALSE}
# First we group the data accordingly, storing it in `pong_data_group`
pong_data_group <- group_by(pong_data, BackgroundColor, PaddleLength)

# And then we summarise it, storing the answer in `total_hits`
pong_data_hits <- summarise(pong_data_group, total_hits = sum(HitOrMiss))

# And filter just the red, small paddle hits
pong_data_hits_red_small <- filter(pong_data_hits, BackgroundColor == "red", PaddleLength == 50)
```

Pipelines allow us to quickly, accurately, and reproducibly, perform an action that would take much longer manually. However we can make our code even more efficient, using less code, by stringing our sequence of functions together using '**pipes**', written as `%>%`. This would look like:

```{r datasummary-pipes, eval = FALSE}
# Same pipeline using pipes
pong_data_hits_red_small <- pong_data %>% 
  group_by(BackgroundColor, PaddleLength) %>% 
  summarise(total_hits = sum(HitOrMiss)) %>%
  filter(BackgroundColor == "red", PaddleLength == 50)
```

Both these chunks show exactly the same procedure, but adding pipes can make code easier to read and follow once you understand piping. 

Code without a pipe would look like 

* `function_name(dataset, arg1, arg2,...,argN)`

but a pipe version would look like 

* `dataset %>% function_name(arg1, arg2,...,argN)`

The premise is that you can pipe (`%>%`) between functions when the **input** of a function is the **output of the previous function**. Alternatively, you can use a pipe to put the data into the first function, as shown directly above.

You can think of the pipe (`%>%`) as saying '**and then**' or '**goes in to**'. E.g. the data goes into this function and then this function and then this function. We will expand on this in the lab where you can ask more questions, but try comparing the two chunks of code above and see if you can match them up.

One last point on pipes is that they can be written in a single line of code but it's much easier to see what the pipe is doing if each function takes its own line. Every time you add a function to the pipeline, remember to add a `%>%` first and **Note that when using separate lines for each function, the `%>%` must appear at the end of the line and not the start of the next line**. Compare the two examples below. The first won't work but the second will because the second puts the pipes at the end of the line where they need to be!

``` {r pipes3, eval = FALSE}
# Piped version that wont work 
data_arrange <- pong_data 
                %>% filter(PaddleLength == "50")
                %>% arrange(BallSpeed) 

# Piped version that will work 
data_arrange <- pong_data %>%
                filter(PaddleLength == "50") %>%
                arrange(BallSpeed) 
```


`r hide("Portfolio Point - Pipes are good for the Environment")`
```{block, type = "info"}
Where piping becomes most useful is when we **string a series of functions together**, rather than using them as separate steps and having to save the data each time under a new variable name and getting ourselves all confused. In the non-piped version we have to create a new variable each time, for example, `data`, `data_filtered`, `data_arranged`, `data_grouped`, `data_summarised` just to get to the final one we actually want, which was `data_summarised`.  This creates a lot of variables and tibbles in our environment and can make everything unclear and eventually slow down our computer. The piped version however uses one variable name, saving space in the environment, and is clear and easy to read. With pipes we skip unnecessary steps and avoid cluttering our environment.
```
`r unhide()`  

<span style="font-size: 22px; font-weight: bold; color: var(--green);">Quickfire Questions</span>

* What does this line of code say? `data %>% filter() %>% group_by() %>% summarise()`: `r mcq(c("take the data and group it and then filter it and then summarise it", answer = "take the data and filter it and then group it and then summarise it", "take the data and summarise it and then filter it and then group it","take the data and group it and then summarise it and then filter it"))`  

**Job Done - PreClass Activity Completed!**

We have now recapped a number of functions and verbs that you will need as the semester goes on.  You will use them in the lab next week so be sure to go over these and try them out to make yourself more comfortable with them. Remember to also start looking back at your first year labs and remembering some of the work you did there.  If you have any questions please post them on the Moodle forum of the slack forum [rguppies.slack.com](https://rguppies.slack.com/) under the channel #level2_labs. Finally, don't forget to add any useful information to your Portfolio before you leave it too long and forget. **Happy Wrangling!**