
## InClass Activity

**One-factor ANOVA: Worked example**

Let's start with some simulated data corresponding to a between-subjects design with three groups (conditions/levels) on one factor (variable). In this hypothetical study, you're investigating the effects of ambient noise on concentration. You have participants transcribe a handwritten document onto a laptop and count the number of typing errors (DV = typos) each participant makes under their respective different conditions:

* while hearing ambient conversation such as you would find in a busy cafe ("cafe" condition); 
* while listening to mellow jazz music ("jazz" condition); 
* or in silence ("silence" condition).  

Again for practice we will only use small, highly under-powered groups. You have three different participants in each condition. As such, your data are as follows:

- **cafe**: 111, 102, 111 
- **jazz**: 89, 127, 90
- **silence**: 97, 85, 88

Below is the decomposition matrix for this data set, based on the GLM: $Y_{ij} = \mu + A_i + S(A)_{ij}$. This is what we did last week in the lab and what you did for the homework activity. You can have a go at creating it yourself from scratch if you like, as good practice, or, in the interests of time, feel free to reveal the code and run that code to create the dmx. 

**Note** that we have also included a column called `sub_id` with a unique identifier for each participant. This is not that important for the `dmx` but we will definitely need it later for running the ANOVA using the `ez::ezANOVA()` function, so let's just include it now so we don't forget.

<div class="solution"><button>Reveal DMX code</button>

```r
dmx <- tibble(sub_id = 1:9,
              i = rep(1:3, each = 3),
              j = rep(1:3, times = 3),
              typos = c(111, 102, 111, 
                    89, 127, 90,
                    97, 85, 88),
              sound = rep(c("cafe", "jazz", "silence"), each = 3)) %>%
  mutate(mu = mean(typos)) %>%
  group_by(i) %>%
  mutate(Ai = mean(typos) - mu) %>%
  ungroup() %>%
  mutate(err = typos - (mu + Ai))
```
</div>


 sub_id    i    j    typos     sound     mu     Ai     err 
--------  ---  ---  -------  ---------  -----  -----  -----
   1       1    1     111      cafe      100     8      3  
   2       1    2     102      cafe      100     8     -6  
   3       1    3     111      cafe      100     8      3  
   4       2    1     89       jazz      100     2     -13 
   5       2    2     127      jazz      100     2     25  
   6       2    3     90       jazz      100     2     -12 
   7       3    1     97      silence    100    -10     7  
   8       3    2     85      silence    100    -10    -5  
   9       3    3     88      silence    100    -10    -2  

And we finished off last week by calculating the Sums of Squares for the different columns. Remember that the Sums of Squares (or often shortend to) is literally squaring the values within a column and summing them up, and is a measure of the variance attributable to that part of the model (or that column). 

The Sums of squares for the above model has the following relationship:

$SS_{total} = SS_{\mu} + SS_{A} + SS_{error}$

* Have a go at calculating the SS of the above `dmx` table using the code we showed you towards the end of the inclass activity last week. If unsure, then the solution is below:

<div class="solution"><button>Calculating Sums of Squares</button>

```r
dat_ss <- dmx %>% 
  summarise(total = sum(typos^2),
            ss_mu = sum(mu^2),
            ss_sound = sum(Ai^2),
            ss_err = sum(err^2))

dat_ss
```

```
## # A tibble: 1 x 4
##   total ss_mu ss_sound ss_err
##   <dbl> <dbl>    <dbl>  <dbl>
## 1 91574 90000      504   1070
```
</div>

We can check that we have calculated everything correctly by observing that based on the relationship:

$SS_{total} = SS_{\mu} + SS_{A} + SS_{error}$

then:

91574 = 90000 + 504 + 1070.

### Task 1

Answer the following questions.

1. Calculate the **corrected total sum of squares** where the corrected total is the total minus the part of the total attributable to the intercept (i.e., the grand mean, $\mu$).

2. What proportion of the corrected total sum of squares attributable to the main effect of `sound`? (**hint**: $SS_{sound} = SS_{A}$)

3. What proportion the corrected total is attributable to residual error? (**hint**: $SS_{error}$)

### Task 2: Mean squares and degrees of freedom

Great, so we now know how to create our decomposition matrix and how to calculate our sums of squares. The only thing left to do is to calculate the F ratio to determine if there is a significant effect between our groups. To do that we first need to calculate some Mean Squares.  But first, as it is always good to have a view of the whole picture, let's not forget that the whole purpose here is to show you where the numbers come from in our quest to determine if there is a significant difference between our groups, or in other words, is there an effect of listening condition on concentration!

You will remember from your lectures and from your reading of Miller & Haden that the F ratio is a ratio of two estimates of population variance:

$F = \frac{MS_{between}}{MS_{within}}$

also sometimes seen as

$F = \frac{MS_{treatment}}{MS_{error}}$

and in Miller and Haden as

$F = \frac{MS_{A}}{MS_{S(A)}}$

And you will also remember that the mean square (MS) is a sums of squares (SS) divided by its degrees of freedom (df):

$MS = \frac{SS}{df}$

So let's put this together.  If we know the SS of our group/treatment ($SS_{A}$ - also called the between variance) and we know the SS of our error/residuals ($SS_{error}$ - also called the within variance), then we can convert both to Mean Squares (MS), basically the average variance for that condition, by dividing them by their respective degrees of freedom (df), and then calculate F by $MS_{A} / MS_{error}$.  If the $MS_error$ is larger than $MS_{A}$ (the group effect) then F will be small and there will be no signficant effect of group - any difference in groups is purely due to individual differences (another way of thinking about error). On the other hand, if $MS_{A}$ (the group effect) is larger than $MS_error$ then F will be large, and depending on how large F is, there may be a significant difference caused by your group variable.

With all that in mind, and it may take a couple of readings, try to answer the following questions (consulting Miller & Haden Ch. 3 and your lecture slides where needed).

1. How many degrees of freedom are there for $A_{i}$, the main effect of `sound`, if $dfA_{i}$ = k - 1?

2. How many error degrees of freedom are there (i.e., for $S(A)_{ij}$), if df = N - $dfA_{i}$ - 1?

3. Calculate $MS_{A}$, where $A$ is the factor `sound`.  **Note:** You can access individual columns in a table using double square brackets `[[]]`; for instance dat_ss[["ss_mu"]] gives you the column `ss_mu` from `dat_ss`. This is an alternative to `$` that some may know; e.g. `dat_ss$mu`.

4. Calculate $MS_{S(A)}$, where $S(A)$ is residual error.

5. Stated in terms of $\mu_{jazz}$, $\mu_{cafe}$, and $\mu_{silence}$, what is the null hypothesis for this specific study of the effects of sound on typographic errors? 
    * Remember that the null says that there are no differences between conditions.
    
### Task 3: F-ratios

Last step, the F ratio.  As above, if the null hypothesis is true, then both estimates of the population variance ($MS_{between}$ and $MS_{within}$) should line up, and the $F$-ratio should approach 1 (because $x/x = 1$). Now we can't expect these two estimates to be **exactly** equal because of sampling bias. So to see how unlikely our observed F-ratio is under the null hypothesis, we have to compare it to the F distribution.

To learn a bit about the F distribution we have created a shiny app to play with.  Shiny Apps are interactive webpages and applications made through R.  Download the app from Moodle or 
<a href = "http://www.psy.gla.ac.uk/~phil/L2Labs_201819/semester_two/lab_03/inclass/F_distribution.zip", target = "_blank">from this link</a>.  Unzip the folder, open up the file app.R through Rstudio, and click **Run app** in RStudio to launch it (found at top right of script window - there is a <span style = "color:green">green play</span> sign). The App window will open showing you some parameters to adjust and a wonderful F distribution plot. Note: When we are finished with the App, close the App window to start typing in console again.

* The F distribution is a representation of the probability of various values of F under the null hypothesis. It depends upon two parameters: $df_{numerator}$ and $df_{denominator}$. Play around with the sliders corresponding to these two parameters and observe how the shape of the distribution changes.

* There is also a slider that lets you specify an observed $F$ ratio (to one digit of precision).  It is represented on the <span style = "color:blue">blue line</span> of the graph.  Move this slider around and watch how the p-values change.  The p-value is the total area under the curve to the right of the blue line.

* The <span style = "color:red">red line</span> on the plot denotes the critical value of F required for a significant difference, given the $\alpha$ (type 1 error rate) and the $df_{numerator}$ and $df_{denominator}$

Try using your data and the app to answer the following questions:

1. From your data, calculate the observed F ratio (called `f_obs`) for the effect of `sound` on `typos` (concentration). (**hint**: $MS_{between} / MS_{within}$

Using the app, set the $\alpha$ to .05, set the degrees of freedom to correspond to those in your study, and set the observed F ratio as close as you can to the value you got in the above question.  

2. Now, according to the app, what is the critical value for $F$ (**hint**: red line)?

3. According to the app, what is the approximate $p$ value associated with your observed $F$ ratio?

4. Based on these values, do you reject or retain the null hypothesis?

**Tricky question:** Note that you can use the distribution functions for $F$ in the same way you did in previous Semester 1 labs (e.g. Lab 4) for the normal distribution (`pnorm()`, `dnorm()`, `qnorm()`) or for the binomial distribution (`pbinom()`, `dbinom()`, `qbinom()`), keeping in mind however that the F distribution, being continuous, is more analogous to the normal distribution.  See `?df` for the distribution functions associated with $F$.

5. Calculate the $p$ value associated with $F_{obs}$ more exactly than the app using the appropriate distribution function.


### Using ez::ezANOVA()

Great, so we have calculated F for this test and made a judgement about whether it is significant or not. But that was quite a long way of doing it, and whilst it is always great to see where the data comes from, you don't want to have to do that each time you run a test.  So now we are going to re-analyse the same dataset, but this time we are going to have the computer do all the computational work for us. 

There are various options for running ANOVAs in R, but the function we will be using for this course is `ezANOVA()` function in the `ez` add-on package.  Note that to use `ezANOVA()` you either have to load in the package using `library("ez")`, or you can call it directly without loading using `ez::ezANOVA()` (the `package_name::function` syntax).  If you're just using the function once, the latter often makes more sense.  The `ez` package is already installed in the Boyd Orr machines so only needs called to the library. On your own machines you will need to install the package if you haven't already done so.

* Read the documentation for `ezANOVA` (type `?ezANOVA` in the console).  It also helps to look at some examples.  Then try to specify the call to `ezANOVA()` so that it reproduces the results you got when you did it by hand above. 

* What do you conclude about the effects of ambient noise on concentration?

#### Hints for ezANOVA

* create a tibble called `dat` keeping only the columns you need from dmx
* you need your dv column, your condition column, and your participant id column that we created at the start
* ezANOVA(data = ?, dv = ?, wid = ?, between = ?)
* you will get two outputs. One is the F-test. One is Levene's homogeniety of variance. Make sure you can identify both.

**Conclusion**

Not much to be honest with you.! F(2, 16) = 5.143, p = .32. As such there is no significant effect of ambient noise on concentration according to this highly underpowered study.

**Job Done!**

Excellent work! And super interesting as well, huh? Quick, everyone to the cafe and don't worry about the typos!!!!

You should now be ready to complete the Homework Assignment for this lab. **The assignment for this Lab is summative and should be submitted through the Moodle Level 2 Assignment Submission Page no later than 1 minute before your next lab.** If you have any questions, please post them on the slack forum under the channel #level2_2018. Finally, don't forget to add any useful information to your Portfolio before you leave it too long and forget.
