## InClass Activity

```{r round2-function-setup, echo=FALSE, warning=FALSE, message=FALSE}
# needed for rounding up from .5 (not default in R)
round2 = function(x, n = 0) {
  posneg = sign(x)
  z = abs(x)*10^n
  z = z + 0.5
  z = trunc(z)
  z = z/10^n
  z*posneg
}

ratings <- read_csv("data/14-s02/inclass/voice_ratings.csv")
acoustics <- read_csv("data/14-s02/inclass/voice_acoustics.csv")
```

You have been reading about regression in Miller and Haden (2013) and have been looking at it in the lectures. Today, to help get a practical understanding of regression, you will be working with real data and using regression to explore the question of whether there is a relationship between voice acoustics and ratings of perceived trustworthiness. 

**The Voice**

The prominent theory of voice production is the **source-filter theory** (Fant, 1960) which suggests that vocalisation is a two step process: air is pushed through the larynx (vocal chords) creating a vibration, i.e. the source, and this is then shaped and moulded into words and utterances as it passes through the neck, mouth and nose, and depending on the shape of those structures at any given time you produce different sounds, i.e. the filter. One common measure of the source is pitch (otherwise called Fundamental Frequency or F0 (F-zero)) (Titze, 1994), which is a measure of the vibration of the vocal chords, in Hertz (Hz); males have on average a lower pitch than females for example. Likewise, one measure of the filter is called formant dispersion (measured again in Hz), and is effectively a measure of the length of someone's vocal tract (or neck). Height and neck length are suggested to be negatively correlated with formant dispersion, so tall people tend to have smaller formant dispersion. So all in, the sound of your voice is thought to give some indication of what you look like.  

More recently, work has focussed on what the sound of your voice suggests about your personality. <a href = "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0090779" target = "_blank">McAleer, Todorov and Belin (2014)</a> suggested that vocal acoustics give a perception of your trustworthiness and dominance to others, regardless of whether or not it is accurate. One extension of this is that trust may be driven by malleable aspects of your voice (e.g. your pitch) but not so much by static aspects of your voice (e.g. your formant dispersion). Pitch is considered malleable because you can control the air being pushed through your vocal chords (though you have no conscious control of your vocal chords), whereas dispersion may be controlled by the structure of your throat which is much more rigid due to muscle, bone, and other things that keep your head attached. This idea of certain traits being driven by malleable features and others by static features was previously suggested by <a href = "https://www.pnas.org/content/105/32/11087" target = "_blank">Oosterhof and Todorov (2008)</a> and has been tested with some validation by <a href = "https://link.springer.com/article/10.1007/s10919-015-0214-8" target = "_blank">Rezlescu, Penton, Walsh, Tsujimura, Scott and Banissy (2015)</a>.

So the research question today is: can vocal acoustics, namely pitch and formant dispersion, predict perceived trustworthiness from a person's voice? We will only look at male voices today, but you have the data for female voices as well should you wish to practice (note that in the field, tendency is to analyse male and female voices separately as they are effectively sexually dimorphic). As such, we hypothesise that **a linear combination of pitch and dispersion will predict perceived vocal trustworthiness in male voices**. This is what we will analyse.

**Let's begin.**

First, to run this analysis you will need to download the data from Moodle or [from here](data/14-s02/inclass/ch14-inclass-data.zip). You will see in this folder that there are two datafiles:

* voice_acoustics.csv - shows the VoiceID, the sex of voice, and the pitch and dispersion values
* voice_ratings.csv - shows the VoiceID and the ratings of each voice by 28 participants on a scale of 1 to 9 where 9 was extremely trustworthy and 1 was extremely untrustworthy

Have a look at the layout of the data and familiarise yourself with it. The ratings data is rather messy and in a different layout to the acoustics but can you tell what is what?

* Looking at the layout of the acoustics data it appears to be in `r mcq(c("long", "wide", answer = "tidy"))`
* Looking at the layout of the ratings data it appears to be in `r mcq(c("long", answer = "wide"))`

We are going to need to do some data-wrangling before we do any analysis!!!

### Task 1: Setup {#Ch14InClassQueT1}

Open a new script or Rmd (depending on how you like to work) and load in the tidyverse, broom, and the two CSV datasets into tibbles called `ratings` and `acoustics`.  Probably best if the ratings are in `ratings` and the acoustics in `acoustics`.

### Task 2: Restructuring the ratings {#Ch14InClassQueT2}

Next we need to calculate a mean rating score for each voice. We are analysing the voices and not specifically what each participant rated each voice as (that is for another year) so we need to average across all participants, their ratings for each individual voice and get a mean rating for each voice. You will see in your data that the voices are identified in the VoiceID column.

Recall the difference between **wide** and **long** data. In wide data, each row represents an individual case, with observations for that case in separate columns; in long data, each row represents a single observation, and the observations are grouped together into cases based on the value of a variable (for these data, the `VoiceID` variable). Before we calculate means, what you need to do is to restructure the ratings data into the appropriate "tidy" format; i.e., so that it looks like the table below.

```{r ratings-wide, echo = FALSE}
ratings_hide <- gather(ratings, participant, rating, P1:P28)
knitr::kable(ratings_hide[1:6,], align = "c", caption = "Gather the data into Tidy format")
```

* Write code to restructure the ratings data as above and store the resulting table as `ratings_tidy`.  Only the first six rows are shown. In the table above you see the first 6 voices all rated by Participant 1.

`r hide("Hint for Task 2")`
```{block, type = "info"}
* gather(data, new_column_name, new_column_name, first-column:last-column)
```
`r unhide()`

```{r reshape, echo = FALSE}
ratings_tidy <- gather(ratings, participant, rating, P1:P28)
```

### Task 3: Calculate mean trustworthiness rating for each voice {#Ch14InClassQueT3}

Now that you've gotten your ratings data into a more tidy format, the next step is to calculate the mean rating (`mean_rating`) for each voice. Remember that each voice is identified by the `VoiceID` variable. Store the resulting table in a variable named `ratings_mean`. 

`r hide("Hint for Task 3")`
```{block, type = "info"}
 * a group_by and summarise would do the trick
 * remember if there are any NAs then na.rm = TRUE would help
```
`r unhide()`

```{r ratings_means, echo=FALSE}
ratings_mean <- ratings_tidy %>% 
  group_by(VoiceID) %>% 
  summarise(mean_rating = mean(rating))
```

### Task 4: Joining the Data together {#Ch14InClassQueT4}

Great! We are so hot at wrangling now we are like hot wrangling irons! Ok but, before we get ahead of ourselves, in order to perform the regression analysis we need to combine the data from `ratings_mean` (the mean ratings) with `acoustics` (the pitch and dispersion ratings). Also, as we said, we only want to analyse Male voices today. 

* Go ahead and join the two tibbles and filter out the Female voices to keep the Male voices only. Call the resulting tibble `joined`. The first few rows should look like this:

```{r combine-ex, echo = FALSE}
joined_hide <- inner_join(ratings_mean, acoustics, "VoiceID") %>% filter(sex == "M")
knitr::kable(joined_hide[1:6,], caption = "Only the Male Voices")
```

`r hide("Hint for Task 4")`
```{block, type = "info"}
* inner_join by the common column in both datasets
* filter to keep just Male voices
```
`r unhide()`

```{r joined, echo=FALSE}
joined <- inner_join(ratings_mean, acoustics, "VoiceID") %>% filter(sex == "M")
```

### Task 5: Scatterplot {#Ch14InClassQueT5}

As always, where possible, it is a good idea to visualise your data. Now that we have all of the variables in one place, reproduce the scatterplot shown below and then try to answer the following questions.

* According to the scatterplot, there appears to be a `r mcq(c("negative relationship", answer = "positive relationship"))` between both pitch and trustworthiness and dispersion and trustworthiness though the relationship with `r mcq(c("dispersion", answer = "pitch"))` seems stronger.

```{r scatter, echo = FALSE, fig.cap='Scatterplot showing the relationship between the voice measures of Dispersion (left) and Pitch (right) and Mean Trustworthiness Rating'}

ggplot(joined, aes(value, mean_rating)) +
  geom_point() +
  geom_smooth(method = "lm") +
  scale_y_continuous(breaks = c(1:7), limits = c(1,7)) +
  labs(x = "Voice Measure (Hz)", y = "Mean Trustworthiness Rating") +
  facet_wrap(~measures, nrow = 1, ncol = 2, scales = "free") +
  theme_classic()
```

`r hide("Hint for Task 5")`
```{block, type = "info"}
* ggplot()
* geom_smooth(method = "lm")
* coord_cartesian or scale_y_continuous
* facet_wrap(scales = "free")
* did you know also that you can control the number of columns and rows in a facet_wrap by adding nrow and ncol?
```
`r unhide()`

### Task 6: Spreading the data {#Ch14InClassQueT6}

Ok so we are starting to get an understanding of our data and we want to start thinking about the regression. However, the regression would be easier to work with if Pitch and Dispersion were in separate columns.  

* Create a new tibble where Pitch and Dispersion data have been split into two columns called `Pitch` and `Dispersion` respectively.

`r hide("Hint for Task 6")`
```{block, type = "info"}
* spread() needs the data, name of the categorical column to spread, and the name of the data to spread
```
`r unhide()`

```{r data-spread, echo = FALSE}
joined_wide <- joined %>% spread(measures, value)
```

### Task 7: The Regressions {#Ch14InClassQueT7}

Excellent, we are now in a position to regress away.  Oh hang on, we should probably check the correlation between Pitch and Dispersion as remember the issue of **collinearity**.  Calculate the correlation between Pitch and Dispersion and fill in this statement. 

* The correlation between Pitch and Dispersion is `r mcq(c(answer = "rho = .239", "rho = -.239", "rho = .186", "rho = -.186"))` which would suggest that we have no issues with collinearity as our two predictors are only slightly correlated and the correlation here is not significant.

Ok, let's do some regression. The `lm()` function in R is the main function we will use to estimate a **L**inear **M**odel (hence the function name `lm`). Use the `lm()` function to run the following three regression models.  

**Simple Linear Regression**

* Run the simple linear regression of predicting trustworthiness mean ratings from Pitch, and store the model in `mod_pitch`
* Run the simple linear regression of predicting trustworthiness mean ratings from Dispersion, and store the model in `mod_disp`

**Multitple Linear Regression**

* Run the multiple linear regression of predicting trustworthiness mean ratings from Pitch and Dispersion, and store the model in `mod_pitchdisp`

Now look at the results of each one in turn, and try to interpret them, using the function `summary()`, e.g. `summary(mod_pitch)`.

`r hide("Hint for Task 7")`
```{block, type = "info"}
**Correlations**

* You should probably use a Spearman correlation for the correlation between Pitch and Dispersion because the scales are very different although measured both in (Hz)
* You may need to refer back to Chapter 10 on correlations to remember how to use `cor.test()`.

**Regressions**

* lm(dv ~ iv, data = my_data) for simple linear regression
* lm(dv ~ iv1 + iv2, data = my_data) for multiple linear regression
```
`r unhide()`

### Task 8: Making interpretations {#Ch14InClassQueT8}

```{r mod1, echo=FALSE}
mod_pitch <- lm(mean_rating ~ Pitch, joined_wide)
```

```{r mod2, echo=FALSE}
mod_disp <- lm(mean_rating ~ Dispersion, joined_wide)
```

```{r mod3, echo=FALSE}
mod_pitchdisp <- lm(mean_rating ~ Pitch + Dispersion, joined_wide)
```

Let's look at the `mod_pitch` model together.

```{r mod1-show}
summary(mod_pitch)
```

From the output we can see that this model, when relating to the population, would predict approximately 30.8% of the variance in trustworthiness ratings (Adjusted-R^2 = .3086). We could also say that a linear regression model revealed that pitch significantly predicted perceived trustworthiness scores in male voices in that as pitch increased so does perceived trustworthiness (b = .0156, t(30) = 3.852, p < .001). (Remember that these are unstandardised coefficients so the "Estimate" would mean that a one unit change in pitch would result in a .0156 unit change in perceived trust, a rather small change.) 

Overall we have a model of small to medium prediction but it is better than no model - or just using mean values as a prediction - as shown by the F-test being significant. Worth also pointing out here that in a simple linear regression the F-test and the t-value for the predictor are the same based on t^2 = F, as seen in Semester 2 Lab 3.

Ok, based on that knowledge, answer the following questions about the two remaining models.

- The dispersion as a predictor by itself model would explain approximately `r mcq(c(answer = "3%","13%","31%","33%"))`
- In fact, the dispersion by itself model is `r mcq(c(answer = "not significant", "significant"))` and therefor `r mcq(c(answer = "no use","very useful"))` as a model
- Looking at the multiple linear regression model, the explained variance is `r mcq(c("3.05%","13.5%",answer = "30.5%","33.5%"))`and as such explains `r mcq(c(answer = "less","more"))` variance than the pitch only model.

What the above should remind you is that it is not the case that simply putting all the possible predictors into a model will make it a better model. For every predictor you add there is a penalty associated with the Adjusted-R^2 and if the explained variance attributable to the new predictor is not greater than the penalty to overall explained variance then you may actually end up with a worse model despite having more predictors.  We will look at model comparison more in the coming months and years but it is always good to keep the rule of parsimony in mind!

### Task 9: Making predictions {#Ch14InClassQueT9}

Congratulations! You have successfully constructed a linear model relating trustworthiness to pitch and dispersion and you can think about applying this knowledge to other challenges - perhaps go look at female voices? However, one last thing you might want to do that we will quickly show you is how to make a prediction using the `predict()` function. One way you use this, though see solutions, is:

```
predict(mod, newdata)
```

where `newdata` is a tibble with new observations on X (e.g. `pitch` or `dispersion`) for which you want to predict the corresponding Y values (`mean_rating`).

* Make a tibble with two columns, one called `Pitch` and one called `Dispersion` - exactly as spelt in the model.  Give `Pitch` a value of 150 Hz (quite a high voice) and give `Dispersion` a value of 1100 Hz - somewhere in the middle.  Now put that tibble, `newdata` into the `predict()` function to run it on the `mod_pitchdisp`

* To one decimal place, what is the predicted trustworthiness rating of a person with 150 Hz Pitch and 1100 Hz Dispersion - `r fitb(5.3, width = 4)`

`r hide("Hint for Task 9")`
```{block, type ="info"}
* tibble(Pitch = Value, Dispersion = Value)
```
`r unhide()`
<br>

**WAIT!** - Didn't we just say that the `mod_pitchdisp` model is not as good as `mod_pitch`. Yep. We did. But we wanted to show you how to enter different predictors into the `predict()` function. So whilst this is a good teaching aid, you are 100% correct in thinking that in reality we would be better making predictions with just the `mod_pitch` model as it explains more variance overall.  Well done for spotting that!

<span style="font-size: 22px; font-weight: bold; color: var(--blue);">Job Done - Activity Complete!</span>

Great! Now you know how to make predictions why not try a few more.  Choose some pitch values see what you get! Go record your voice. Extract the pitch using something like <a href = "http://www.fon.hum.uva.nl/praat/" target = "_blank">PRAAT</a>. Put it in the `predict()` function. Get a rating of trustworthiness for your voice. Go run a study that has your voice rated for trustworthiness and see how close the model was. Given the explained variance is not great it probably won't be that close but you start to see how, in principle, the idea of regression and prediction of relationships works. The greater the explained variance of your predictors, the better your prediction will be for a novel participant/observation/event!

You should now be ready to complete the Homework Assignment for this lab. **The assignment for this Lab is summative and should be submitted through the Moodle Level 2 Assignment Submission Page no later than 1 minute before your next lab.** If you have any questions, please post them on the slack forum under the channel **#level2_2019**. Finally, don't forget to add any useful information to your Portfolio before you leave it too long and forget.
